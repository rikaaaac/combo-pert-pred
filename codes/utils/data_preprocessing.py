# -*- coding: utf-8 -*-
"""data_preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_0cyJuOSAtXHNQp_XdeuAD3KETTvKoND
"""

# mount drive
from google.colab import drive
drive.mount('/content/drive')

! gcloud auth list # check authentication status

! gcloud auth login --no-launch-browser

# install gcloud
! gcloud config set project azizilab-aml

# SSH and run commands
! gcloud compute ssh aymeric-instance-19 --zone=us-east4-c --command="nvidia-smi"

! pip install scanpy --quiet
! pip install anndata --quiet
! pip install scikit-misc --quiet

import scanpy as sc
import anndata as ad
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from scipy import io
import gzip

"""# filtered_perturbseq

## load filtered data
"""

path = '/content/drive/MyDrive/ml_stats_genomics/project/dataset/filtered_perturbseq/'

# load matrix
print("Loading expression matrix...")
matrix_file = path + "GSE133344_filtered_matrix.mtx.gz"
matrix = io.mmread(matrix_file).T.tocsr()  # transpose to cells x genes
print(f"Matrix shape: {matrix.shape} (cells x genes)")

# load barcodes/cell IDs
print("Loading cell barcodes...")
with gzip.open(path + "GSE133344_filtered_barcodes.tsv.gz", 'rt') as f:
    barcodes = pd.read_csv(f, header=None, sep='\t')
    barcodes = barcodes[0].values
print(f"Number of cells: {len(barcodes)}")

# load genes
print("Loading gene names...")
with gzip.open(path + "GSE133344_filtered_genes.tsv.gz", 'rt') as f:
    genes = pd.read_csv(f, header=None, sep='\t')
    gene_names = genes[1].values  # Use gene symbols (column 1)
print(f"Number of genes: {len(gene_names)}")

# load cell identities (perturbation labels)
print("Loading cell identities (perturbation labels)...")
with gzip.open(path + "GSE133344_filtered_cell_identities.csv.gz", 'rt') as f:
    cell_identities = pd.read_csv(f)
print(f"Cell identities shape: {cell_identities.shape}")
print(f"Columns: {cell_identities.columns.tolist()}")
cell_identities.head()

"""## create adata"""

# create AnnData object
adata = sc.AnnData(X=matrix)
adata.obs_names = barcodes
adata.var_names = gene_names
adata.var_names_make_unique()

adata

# add perturbation metadata
# match cell barcodes to identities
cell_id_dict = dict(zip(cell_identities['cell_barcode'], cell_identities['guide_identity']))

adata

adata.obs['perturbation'] = [cell_id_dict.get(bc, 'unknown') for bc in adata.obs_names]

print(f"  AnnData object created: {adata}")
print(f"  Perturbations found: {adata.obs['perturbation'].nunique()}")

adata.obs

"""## basic QC and filtering"""

# calculate QC metrics
sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True)

print("\n  QC Statistics (before filtering):")
print(f"    Total cells: {adata.n_obs}")
print(f"    Total genes: {adata.n_vars}")
print(f"    Mean genes per cell: {adata.obs['n_genes_by_counts'].mean():.0f}")
print(f"    Mean counts per cell: {adata.obs['total_counts'].mean():.0f}")

# filter cells (basic filtering)
print("\n  Filtering cells...")
sc.pp.filter_cells(adata, min_genes=200)
print(f"    Cells after filtering (min_genes=200): {adata.n_obs}")

# filter genes
print("\n  Filtering genes...")
sc.pp.filter_genes(adata, min_cells=3)
print(f"    Genes after filtering (min_cells=3): {adata.n_vars}")

print("\n  QC Statistics (after filtering):")
print(f"    Total cells: {adata.n_obs}")
print(f"    Total genes: {adata.n_vars}")
print(f"    Mean genes per cell: {adata.obs['n_genes_by_counts'].mean():.0f}")
print(f"    Mean counts per cell: {adata.obs['total_counts'].mean():.0f}")

"""## normalization"""

# store raw counts
adata.raw = adata

# normalize to median total counts
print("  Normalizing to median total counts...")
sc.pp.normalize_total(adata, target_sum=None)

# log transform
print("  Log transforming (log1p)...")
sc.pp.log1p(adata)

print("  Normalization complete!")

adata.X.max()

"""## scaling and PCA"""

# scale data (for PCA)
print("  Scaling data (z-score normalization)...")
sc.pp.scale(adata, max_value=10)

# run PCA
print("  Computing PCA...")
sc.tl.pca(adata, svd_solver='arpack', n_comps=30)
print("  PCA complete!")

"""## UMAP"""

# compute neighborhood graph
print("   Computing neighborhood graph...")
sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30)

# Compute UMAP
print("   Computing UMAP embedding...")
sc.tl.umap(adata)
print("   UMAP complete!")

adata

"""## annotate perturbation type"""

adata.obs['perturbation'] = adata.obs['perturbation'].str.lower()

adata.obs['perturbation']

# classifiy perturbation types
def classify_perturbation(adata, perturbation_col='perturbation', new_col='perturbation_type'):
    """
    naming convention follows: Gene1_Gene2__Gene1_Gene2
    - NegCtrl0_NegCtrl0__NegCtrl0_NegCtrl0 -> control
    - TSC22D1_NegCtrl0__TSC22D1_NegCtrl0 -> single
    - KLF1_MAP2K6__KLF1_MAP2K6 -> combo
    """

    def classify_single_perturbation(perturbation_id):
        """
        classify a single perturbation ID: control, single, combo
        """
        # handle missing/NaN values
        if pd.isna(perturbation_id):
            return 'unknown'

        # split by double underscore to get the two halves (should be identical)
        parts = perturbation_id.split('__')
        if len(parts) != 2:
            return 'unknown'

        # take the first part and split by single underscore to get the two genes
        genes = parts[0].split('_')
        if len(genes) != 2:
            return 'unknown'

        gene1, gene2 = genes

        # classify based on whether genes are controls or targets
        control_patterns = ['NegCtrl', 'negctrl', 'ctrl', 'control', 'NT']  # common control naming

        is_gene1_control = any(ctrl in gene1 for ctrl in control_patterns)
        is_gene2_control = any(ctrl in gene2 for ctrl in control_patterns)

        if is_gene1_control and is_gene2_control:
            return 'control'
        elif is_gene1_control or is_gene2_control:
            return 'single'
        else:
            return 'combo'

    # apply classification to all perturbations
    adata.obs[new_col] = adata.obs[perturbation_col].apply(classify_single_perturbation)

    # print summary statistics
    print(f"Perturbation classification summary:")
    print(f"{'='*50}")
    classification_counts = adata.obs[new_col].value_counts()
    for pert_type, count in classification_counts.items():
        percentage = (count / len(adata)) * 100
        print(f"{pert_type:10s}: {count:6d} cells ({percentage:5.2f}%)")
    print(f"{'='*50}")
    print(f"Total cells: {len(adata)}")

    return adata


def extract_perturbed_genes(adata, perturbation_col='perturbation', gene1_col='gene1', gene2_col='gene2'):
    """
    extract individual gene names from perturbation identifiers
    """

    def parse_genes(perturbation_id):
        """parse gene names from perturbation identifier."""
        if pd.isna(perturbation_id):
            return pd.Series({'gene1': np.nan, 'gene2': np.nan})

        parts = perturbation_id.split('__')
        if len(parts) != 2:
            return pd.Series({'gene1': np.nan, 'gene2': np.nan})

        genes = parts[0].split('_')
        if len(genes) != 2:
            return pd.Series({'gene1': np.nan, 'gene2': np.nan})

        return pd.Series({'gene1': genes[0], 'gene2': genes[1]})

    # extract genes
    gene_df = adata.obs[perturbation_col].apply(parse_genes)
    adata.obs[gene1_col] = gene_df['gene1']
    adata.obs[gene2_col] = gene_df['gene2']

    return adata

if __name__ == "__main__":
    adata = classify_perturbation(adata)
    adata = extract_perturbed_genes(adata)
    print("\nExample classifications:")
    print(adata.obs[['perturbation', 'perturbation_type', 'gene1', 'gene2']].head(10))

print(f'{adata.obs['perturbation'].nunique()}')

print(adata.obs.groupby('perturbation_type')['perturbation'].nunique())

"""## UMAP for perturbation types"""

fig, ax = plt.subplots(1, 1, figsize=(10, 8))

sc.pl.umap(adata, color='perturbation_type',
           title='UMAP: Norman et al. Perturb-seq Data',
           palette={'control': '#2ecc71',
                   'single': '#e74c3c',
                   'combo': '#3498db',
                    'unknown': '#fc7703'},
           ax=ax, show=False, frameon=False, size=20, alpha=0.7,
           legend_loc='right margin', legend_fontsize=11)

"""All perturbation types are heavily overlapping in the gene expression space, as also seen in the Norman et al. paper."""

adata

sc_adata = sc.read('/content/drive/MyDrive/ml_stats_genomics/project/dataset/sclambda_adata_norman_preprocessed.h5ad')
sc_adata

sc_adata.obs.groupby('nperts')['perturbation'].nunique()

adata.obs.groupby('perturbation_type')['perturbation'].nunique()

"""# raw_perturbseq"""

path = '/content/drive/MyDrive/ml_stats_genomics/project/dataset/raw_perturbseq/'

# load matrix file
adata = sc.read_mtx(path+'GSE133344_raw_matrix.mtx.gz').T

adata

# load barcodes and genes
barcodes = pd.read_csv(path+'GSE133344_raw_barcodes.tsv.gz', header=None, sep='\t')
genes = pd.read_csv(path+'GSE133344_raw_genes.tsv.gz', header=None, sep='\t')

adata.obs_names = barcodes[0].values
adata.var_names = genes[1].values

adata.var

# load cell identities - this is perturbation assignment
cell_ids = pd.read_csv(path+'GSE133344_raw_cell_identities.csv.gz', index_col=0)
adata.obs = adata.obs.join(cell_ids)

cell_ids

adata.obs

adata = adata[~adata.obs['guide_identity'].isna()].copy() # remove cells with no guide identity
adata

adata.obs

# calculate UMI per cell
adata.obs['n_counts'] = np.array(adata.X.sum(axis=1)).flatten()
adata.obs['n_genes'] = np.array((adata.X > 0).sum(axis=1)).flatten()

# Norman et al. filter: keep cells with >= 2000 UMIs
# they used raw data because "cellranger's cell barcode calling tends to remove cells bearing perturbations that induce low UMI counts"
n_before = adata.n_obs
adata = adata[adata.obs['n_counts'] >= 2000, :].copy()

adata.obs

guide_col = 'guide_identity'
adata.obs['raw_identity'] = adata.obs[guide_col].astype(str)

def parse_norman_identity(x):
    """parse Norman format: GENE1_guide1__GENE2_guide2"""
    if pd.isna(x) or x == 'nan':
        return [], 'unknown'

    x = str(x)

    # Split by double underscore to get the two constructs
    # Take just the first half (they're duplicated)
    if '__' in x:
        first_half = x.split('__')[0]
    else:
        first_half = x

    # Split by single underscore to get gene pairs
    parts = first_half.split('_')

    # Extract genes (every other element, genes are at even indices)
    # Format is GENE1_GENE2 after taking first half
    genes = []
    for i, part in enumerate(parts):
        # Check if it's a control/negative control
        if 'NegCtrl' in part or 'ctrl' in part.lower():
            continue
        genes.append(part)

    # Classify
    if len(genes) == 0:
        return genes, 'control'
    elif len(genes) == 1:
        return genes, 'single'
    elif len(genes) == 2:
        return genes, 'double'
    else:
        return genes, 'multiplet'

# Apply parsing
parsed = adata.obs['raw_identity'].apply(parse_norman_identity)
adata.obs['target_genes'] = parsed.apply(lambda x: x[0])
adata.obs['perturbation_type'] = parsed.apply(lambda x: x[1])
adata.obs['num_targets'] = adata.obs['target_genes'].apply(len)

# Create clean perturbation label (sorted gene names joined)
adata.obs['perturbation'] = adata.obs['target_genes'].apply(
    lambda x: '+'.join(sorted(x)) if len(x) > 0 else 'control'
)

print(f"\n  Perturbation types:")
print(adata.obs['perturbation_type'].value_counts())

adata.obs

adata.obs.groupby('num_targets')['perturbation'].nunique()

if 'perturbation_type' in adata.obs.columns:
    n_before = adata.n_obs
    # Keep only control, single, and double perturbations
    adata = adata[adata.obs['perturbation_type'].isin(['control', 'single', 'double'])].copy()
    adata

# basic filters
sc.pp.filter_genes(adata, min_cells=10)

# Norman normalizes to median UMI count of control cells
if 'perturbation_type' in adata.obs.columns:
    control_mask = adata.obs['perturbation_type'] == 'control'
    if control_mask.sum() > 0:
        control_median_umi = adata.obs.loc[control_mask, 'n_counts'].median()
        print(f"  Control cells: {control_mask.sum():,}")
        print(f"  Median UMI in controls: {control_median_umi:.0f}")
        target_sum = control_median_umi
    else:
        target_sum = adata.obs['n_counts'].median()
        print(f"  No control cells found, using overall median: {target_sum:.0f}")
else:
    target_sum = adata.obs['n_counts'].median()
    print(f"  Using overall median UMI: {target_sum:.0f}")

# normalize to target sum (like Norman's equalize_UMI_counts)
sc.pp.normalize_total(adata, target_sum=target_sum)
print(f"  Normalized all cells to {target_sum:.0f} total counts")

# log transform
sc.pp.log1p(adata)
print("  Applied log1p transformation")

# store raw counts
adata.raw = adata

# Norman uses genes with mean > 0.5, we'll just use scanpy's hvg function
sc.pp.highly_variable_genes(adata, n_top_genes=2000, flavor='seurat_v3', span=0.3)

adata

adata.obs

adata.obs['target_genes'] = adata.obs['target_genes'].astype(str)

del adata.obs['target_genes']

# Convert all 'object' dtype columns to 'category' dtype for robust saving
for col in adata.obs.select_dtypes(include='object').columns:
    adata.obs[col] = adata.obs[col].astype('category')

adata.write_h5ad('/content/drive/MyDrive/ml_stats_genomics/project/dataset/norman_perturbseq_preprocessed.h5ad')